{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44b5a63-de83-462d-ad0b-42d4f7bc4f56",
   "metadata": {},
   "source": [
    "# An Endpoint using BERT large model (uncased) with the MS_MARCO dataset\n",
    "\n",
    "# Part 1: DATA CLEANING\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "Bidirectional Encoder Representations from Transformers (BERT) is a pre-trained language model that \n",
    "has achieved state-of-the-art results on numerous natural language processing (NLP) tasks. BERT is a \n",
    "transformer-based model, which was fine-tuned for various NLP tasks, including question answering. \n",
    "The Stanford Question Answering Dataset (SQuAD) is one such task where BERT has achieved \n",
    "significant accuracy compared with other models. However, current research also indicates that \n",
    "tuning BERT with new datasets can lead to further improvements in its performances for specific \n",
    "tasks. In this proposal, we suggest fine-tuning a pre-trained BERT large model (uncased) with the \n",
    "ms_marco dataset using whole word masking and incorporating a fine-tuning approach to improve its \n",
    "performances. \n",
    "\n",
    "The BERT model is based on the concept of pre-training, as well as fine-tuning, a NLP task. The pre\u0002training process is based on unsupervised objectives, such as the masked language model and the \n",
    "next sentence prediction task, to learn contextual representations of words. The fine-tuning process, \n",
    "on the other hand, uses supervised training, where the learned pre-trained knowledge is combined \n",
    "with task-specific datasets to achieve be∆©er performances.\n",
    "\n",
    "MS_MARCO is a dataset consisting of a large collection of real-world queries and corresponding \n",
    "passages that aims to facilitate research in question-answer matching and ranking. It contains more \n",
    "than 1 million queries and over 8 million passages, making it one of the largest publicly available \n",
    "datasets of its kind. Each query in the dataset was generated by real users of the Bing search engine \n",
    "and is paired with relevant passages retrieved from web pages. The dataset is designed to enable \n",
    "researchers to develop and evaluate machine learning models for natural language processing tasks \n",
    "such as question answering, information retrieval, and passage ranking. The dataset also includes \n",
    "information about the relevance of passages to queries, allowing for the evaluation of ranking \n",
    "algorithms. Overall, the MS MARCO v1.2 dataset is a valuable resource for anyone interested in \n",
    "developing and evaluating algorithms for natural language understanding tasks.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Our proposal is to use the BERT large model (uncased) with the MS_MARCO dataset using whole \n",
    "word masking as an endpoint to answer question. For this we will go through the following steps: \n",
    "* Preparing the data: We will use the MS_MARCO dataset to fine-tune the BERT large model. We will construct a train and test set from the available dataset for fine-tuning. \n",
    "* Fine-tuning the model: We will fine-tune the pre-trained BERT model with the MS_MARCO dataset using whole word masking. We will use the Adam optimizer for training and evaluate model performance based on F1 score. \n",
    "* Evaluating the model: We will evaluate the fine-tuned model's performance based on MS_Marco's benchmarking metrics. The key evaluation measures will be the F1-score and the exact match (EM) score. \n",
    "* Deploy the model. \n",
    "* Scale the model so that we can make this application available to a lot more users. \n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e7fde85-6807-455b-85a3-080d4dd6cd65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94fe1e17-3f76-4546-9ab0-26522d244e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 01\n",
    "import sagemaker\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec75b8f-7579-464f-b833-61e1cf1df9ca",
   "metadata": {},
   "source": [
    "Now let's bring in the Python libraries that we'll use throughout the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84c4b413-9f7b-439f-aae6-8b4d69296625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# cell 02\n",
    "!pip install -qU datasets\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker \n",
    "import zipfile     # Amazon SageMaker's Python SDK provides many helper functions\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffa35c-c443-4d5a-92ae-d5e57bde9e16",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Data\n",
    "Let's start by importing the dataset from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b479e8e-0283-43ec-8783-8473043a4961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ms_marco (/media/data_files/github/website_tutorials/data/ms_marco/v1.1/1.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d82ba9f2f54609bf97b82576171ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_data, train_data, test_data = load_dataset('ms_marco', 'v1.1', split =['validation','train', 'test'], cache_dir='/media/data_files/github/website_tutorials/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b46f6d-bb76-4d75-89ca-d381c16ec1c4",
   "metadata": {},
   "source": [
    "Now lets read this into a Pandas data frame and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c40db3b5-a451-4a87-a815-ec25762f4e89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Approximately $15,000 per year.]</td>\n",
       "      <td>{'is_selected': [1, 0, 0, 0, 0, 0], 'passage_t...</td>\n",
       "      <td>walgreens store sales average</td>\n",
       "      <td>9652</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[$21,550 per year, The average hourly wage for...</td>\n",
       "      <td>{'is_selected': [0, 1, 0, 0, 0, 0, 0, 0], 'pas...</td>\n",
       "      <td>how much do bartenders make</td>\n",
       "      <td>9653</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A boil, also called a furuncle, is a deep fol...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 0, 1, 0], 'pas...</td>\n",
       "      <td>what is a furuncle boil</td>\n",
       "      <td>9654</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0                  [Approximately $15,000 per year.]   \n",
       "1  [$21,550 per year, The average hourly wage for...   \n",
       "2  [A boil, also called a furuncle, is a deep fol...   \n",
       "\n",
       "                                            passages  \\\n",
       "0  {'is_selected': [1, 0, 0, 0, 0, 0], 'passage_t...   \n",
       "1  {'is_selected': [0, 1, 0, 0, 0, 0, 0, 0], 'pas...   \n",
       "2  {'is_selected': [0, 0, 0, 0, 0, 0, 1, 0], 'pas...   \n",
       "\n",
       "                           query  query_id   query_type wellFormedAnswers  \n",
       "0  walgreens store sales average      9652      numeric                []  \n",
       "1    how much do bartenders make      9653      numeric                []  \n",
       "2        what is a furuncle boil      9654  description                []  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([pd.DataFrame(validation_data), pd.DataFrame(train_data), pd.DataFrame(test_data)],ignore_index=True)\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22b5f05f-6d1d-4013-8249-54767a96879b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name_raw = 'MS_Marco_raw.csv' \n",
    "data.to_csv(file_name_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe5e162-9619-458c-9e96-d3e162788f2c",
   "metadata": {},
   "source": [
    "We will store this natively in S3 to then process it with SageMaker Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e26078e-ecc9-4531-b7e3-00f88964eba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import Session\n",
    "\n",
    "prefix = 'final_project'\n",
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file(file_name_raw, bucket, f'{prefix}/raw_data/MS_Marco_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69b272-466a-4206-b002-8e47f81acd0b",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engineering \n",
    "\n",
    "Here, we'll import the dataset and transform it with SageMaker Processing, which can be used to process terabytes of data in a SageMaker-managed cluster separate from the instance running your notebook server.\n",
    "\n",
    "For this project, we're using a SageMaker prebuilt Scikit-learn container, which includes many common functions for processing data. Moreover, when the job is complete, SageMaker Processing will automatically uploads the transformed data to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b9a05-e955-42c4-a1dd-4f46642ccc7a",
   "metadata": {},
   "source": [
    "## STEP 1: let's analyse the data to know what to do for the cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67218831-26f3-4971-9479-e87c5e79ab69",
   "metadata": {},
   "source": [
    "Lets show the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4904601-ca87-459a-ae0d-b4668ac1a0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Approximately $15,000 per year.]</td>\n",
       "      <td>{'is_selected': [1, 0, 0, 0, 0, 0], 'passage_t...</td>\n",
       "      <td>walgreens store sales average</td>\n",
       "      <td>9652</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[$21,550 per year, The average hourly wage for...</td>\n",
       "      <td>{'is_selected': [0, 1, 0, 0, 0, 0, 0, 0], 'pas...</td>\n",
       "      <td>how much do bartenders make</td>\n",
       "      <td>9653</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A boil, also called a furuncle, is a deep fol...</td>\n",
       "      <td>{'is_selected': [0, 0, 0, 0, 0, 0, 1, 0], 'pas...</td>\n",
       "      <td>what is a furuncle boil</td>\n",
       "      <td>9654</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0                  [Approximately $15,000 per year.]   \n",
       "1  [$21,550 per year, The average hourly wage for...   \n",
       "2  [A boil, also called a furuncle, is a deep fol...   \n",
       "\n",
       "                                            passages  \\\n",
       "0  {'is_selected': [1, 0, 0, 0, 0, 0], 'passage_t...   \n",
       "1  {'is_selected': [0, 1, 0, 0, 0, 0, 0, 0], 'pas...   \n",
       "2  {'is_selected': [0, 0, 0, 0, 0, 0, 1, 0], 'pas...   \n",
       "\n",
       "                           query  query_id   query_type wellFormedAnswers  \n",
       "0  walgreens store sales average      9652      numeric                []  \n",
       "1    how much do bartenders make      9653      numeric                []  \n",
       "2        what is a furuncle boil      9654  description                []  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf9f87-cb20-4322-9064-9aed07624bb6",
   "metadata": {},
   "source": [
    "- Let's check if all the questions have an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b30ef881-a948-408c-88cf-282057b5e110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2727"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = data['answers'].apply(lambda x: ''.join(x))\n",
    "len(test1[test1==''])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c215f118-6f27-494a-9b39-633dd2d90d69",
   "metadata": {},
   "source": [
    "Rows with no answer exist so we'll have to delete these rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9e5ab-eba1-4cf5-adb0-03eea3d798d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Let's see now is each answer has a context by seeing if there is a text selected (in is_selected) but without including the ones concerned about the previous test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "040812ab-a795-492d-94e8-0323ae73ca16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_itertools import locate\n",
    "test2 = data.passages.apply(lambda x: list(locate(x[\"is_selected\"], lambda y: y == 1)) if sum(x[\"is_selected\"])>0 else '')\n",
    "test2 = test2[test2==''].index.isin(test1[test1==''].index)\n",
    "len(list(locate(test2, lambda y: y == False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5558f55-d566-434a-a478-d077c939754f",
   "metadata": {},
   "source": [
    "We still have answers without passage text selected so we'll delete these elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516405c4-6b13-4685-a0af-44e886fccc3c",
   "metadata": {},
   "source": [
    "- The column wellFormed seems to be only composed of empty list but "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be985dd6-bc02-47a5-99c9-75b29c087270",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [answers, passages, query, query_id, query_type, wellFormedAnswers]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['wellFormedAnswers'].str.len()!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af38cc6-bfe0-4a50-b6c1-f533ffd3fd7c",
   "metadata": {},
   "source": [
    "It is the case so the column is not really useful and we'll drop it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c7af9-0f33-4b1f-a055-948da1a19053",
   "metadata": {},
   "source": [
    "- Then what we see is that the column \"passage\" seems to have to much information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6f2ef-249e-4bbc-8b77-c9c9d53aefc7",
   "metadata": {},
   "source": [
    "For only trainning we only need the context which is the 'passage_text. Also, some cleanig seems to be needed it term of regex and we'll try to solv that problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15aa89-2919-4fa0-8afc-556940644f5a",
   "metadata": {},
   "source": [
    "- let's see if query_id need to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "398e28c8-9edd-4369-819e-c292b227acad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.query_id.unique()) == len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c50e74-dbb5-4e62-8834-0ed0d20e7344",
   "metadata": {},
   "source": [
    "We have the right count of query_id so no cleaning needed for this column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f61819-a802-479c-9f54-7af11001d502",
   "metadata": {},
   "source": [
    "- finally let's study the column query_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eabb63fe-7d88-4198-b0b0-0c3a8638d6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description    55684\n",
       "numeric        28291\n",
       "entity         10485\n",
       "location        5068\n",
       "person          2495\n",
       "Name: query_type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224beba-f337-4082-a09d-f3be5855ea07",
   "metadata": {},
   "source": [
    "So this column is composed of 5 categories and no 'na' values seems to be present so for now we don't need to modify this column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b829f57-b502-470a-9e75-8c40cd5866e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 2: Apply modification on dataset and split train/test/validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3882af1b-cf1f-445c-ad84-7ed8345641e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install -qU emoji\n",
    "import emoji\n",
    "\n",
    "def text_cleaning(text):\n",
    "    \n",
    "    cleaned_text = cleaned_text.replace('..','.')\n",
    "    for character in text:\n",
    "        if character in emoji.UNICODE_EMOJI or (character=='.'):\n",
    "                cleaned_text = cleaned_text.replace(character,'')\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "673dab9e-808d-4f8d-b920-66555f3804c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from more_itertools import locate\n",
    "\n",
    "#CHANGE 1: split passage column dict into 3 column\n",
    "data = pd.concat([data.drop(['passages'], axis=1),\n",
    "                data['passages'].apply(pd.Series)], axis=1)\n",
    "\n",
    "#CHANGE 2: change type colummn answers from list to string\n",
    "data['answers'] = data['answers'].apply(lambda x: ''.join(x))\n",
    "\n",
    "#CHANGE 3: change is selected mapping to list of index of 'passage text' concerned for the answer\n",
    "data['is_selected'] = data['is_selected'].apply(lambda x: list(locate(x,lambda y: y==1)) if 1 in x else '') \n",
    "\n",
    "#CHANGE 4: drop rows with no indicator of passage_text (no index mapped)\n",
    "data = data[data['is_selected']!=''].reset_index(drop=True)\n",
    "\n",
    "#CHANGE 5: create context which is composed of 1 or multiple text of passage_text refered in is_selected as the right reference(s)\n",
    "data['context'] = data.apply(lambda x: str(x['passage_text'][x['is_selected'][0]]) if len(x['is_selected'])==1 else ' '.join(x['passage_text'][i] for i in x['is_selected']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d25bb37-cf2e-4468-b7f0-a876983b9583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_type</th>\n",
       "      <th>wellFormedAnswers</th>\n",
       "      <th>is_selected</th>\n",
       "      <th>passage_text</th>\n",
       "      <th>url</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approximately $15,000 per year.</td>\n",
       "      <td>walgreens store sales average</td>\n",
       "      <td>9652</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[The average Walgreens salary ranges from appr...</td>\n",
       "      <td>[http://www.indeed.com/cmp/Walgreens/salaries,...</td>\n",
       "      <td>The average Walgreens salary ranges from appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$21,550 per yearThe average hourly wage for a ...</td>\n",
       "      <td>how much do bartenders make</td>\n",
       "      <td>9653</td>\n",
       "      <td>numeric</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[A bartender‚Äôs income is comprised mostly of t...</td>\n",
       "      <td>[http://www.breakintobartending.com/how-much-d...</td>\n",
       "      <td>According to the Bureau of Labor Statistics, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A boil, also called a furuncle, is a deep foll...</td>\n",
       "      <td>what is a furuncle boil</td>\n",
       "      <td>9654</td>\n",
       "      <td>description</td>\n",
       "      <td>[]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[Knowledge center. A boil, also known as a fur...</td>\n",
       "      <td>[http://www.medicalnewstoday.com/articles/1854...</td>\n",
       "      <td>A boil, also called a furuncle, is a deep foll...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  \\\n",
       "0                    Approximately $15,000 per year.   \n",
       "1  $21,550 per yearThe average hourly wage for a ...   \n",
       "2  A boil, also called a furuncle, is a deep foll...   \n",
       "\n",
       "                           query  query_id   query_type wellFormedAnswers  \\\n",
       "0  walgreens store sales average      9652      numeric                []   \n",
       "1    how much do bartenders make      9653      numeric                []   \n",
       "2        what is a furuncle boil      9654  description                []   \n",
       "\n",
       "  is_selected                                       passage_text  \\\n",
       "0         [0]  [The average Walgreens salary ranges from appr...   \n",
       "1         [1]  [A bartender‚Äôs income is comprised mostly of t...   \n",
       "2         [6]  [Knowledge center. A boil, also known as a fur...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  [http://www.indeed.com/cmp/Walgreens/salaries,...   \n",
       "1  [http://www.breakintobartending.com/how-much-d...   \n",
       "2  [http://www.medicalnewstoday.com/articles/1854...   \n",
       "\n",
       "                                             context  \n",
       "0  The average Walgreens salary ranges from appro...  \n",
       "1  According to the Bureau of Labor Statistics, t...  \n",
       "2  A boil, also called a furuncle, is a deep foll...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6572969a-27d4-4421-9e9f-e535cb729715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-834242159264/final_project/input_data/MS_Marco.csv'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'MS_Marco.csv' \n",
    "data.to_csv(file_name)\n",
    "\n",
    "s3.meta.client.upload_file(file_name, bucket, f'{prefix}/input_data/MS_Marco.csv')\n",
    "\n",
    "sess = Session()\n",
    "input_source = sess.upload_data(file_name, bucket=bucket, key_prefix=f'{prefix}/input_data')\n",
    "input_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60f1c8c7-4cc5-404a-b891-86e897772079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "def _parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='MS_Marco.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    parser.add_argument('--categorical_features', type=str, default='answers, passages, query, query_id, query_type, wellFormedAnswers')\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    # Load data\n",
    "    df = pd.read_csv(os.path.join(args.filepath, args.filename))\n",
    "    \n",
    "    # CHANGE 1: drop useless column\n",
    "    df = df.drop(['wellFormedAnswers','is_selected','passage_text','url'], axis=1)\n",
    "\n",
    "    # CHANGE 2: drop elements that have no answers\n",
    "    df = df[df[\"answers\"]!=''].reset_index(drop=True)\n",
    "    \n",
    "    # CHANGE 3: change query_type column so it we'll be easier to use\n",
    "    df['query_type'].replace(to_replace=df.query_type.unique(), value=np.arange(1,len(df.query_type.unique())+1), inplace=True)\n",
    "\n",
    "    # CHANGE 4: deletion of rows with answers without context (df['context'][i]=='')\n",
    "    df = df[df['context']!=''].reset_index(drop=True)\n",
    "    \n",
    "    # Train, test, validation split\n",
    "    train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=42), [int(0.7 * len(df)), int(0.9 * len(df))])   # Randomly sort the data then split out first 70%, second 20%, and last 10%\n",
    "    \n",
    "    # Local store\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=True)\n",
    "    test_data.to_csv(os.path.join(args.outputpath, 'test/test.csv'), index=False, header=True)\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=True)\n",
    "    print(\"## Processing complete. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d675be8-0ee7-4753-afc0-50b46ece5208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-834242159264/final_project/train \n",
      " s3://sagemaker-us-east-1-834242159264/final_project/validation \n",
      " s3://sagemaker-us-east-1-834242159264/final_project/test\n"
     ]
    }
   ],
   "source": [
    "train_path = f\"s3://{bucket}/{prefix}/train\"\n",
    "validation_path = f\"s3://{bucket}/{prefix}/validation\"\n",
    "test_path = f\"s3://{bucket}/{prefix}/test\"\n",
    "print(train_path,'\\n',validation_path,'\\n',test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e04fb1-ff3f-4ad4-aa52-4b5bd1a001c9",
   "metadata": {},
   "source": [
    "Before starting the SageMaker Processing job, we instantiate a `SKLearnProcessor` object.  This object allows you to specify the instance type to use in the job, as well as how many instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bfd94f3-f5c3-442c-ad6a-00dc9abd88ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker:Creating processing-job with name project-cleaning-2023-06-11-10-19-25-285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34m## Processing complete. Exiting.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cell 08\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=get_execution_role(),\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1, \n",
    "    base_job_name='project-cleaning'\n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code='preprocessing.py',\n",
    "    # arguments = ['arg1', 'arg2'],\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_source, \n",
    "            destination=\"/opt/ml/processing/input/\",\n",
    "            s3_input_mode=\"File\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_data\", \n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=train_path,\n",
    "        ),\n",
    "        ProcessingOutput(output_name=\"validation_data\", source=\"/opt/ml/processing/output/validation\", destination=validation_path),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/output/test\", destination=test_path),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8c447b9-d9cf-448f-8b34-9b01044911ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-11 10:24:08   43642596 train.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $train_path/"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
